{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"id":"7H420KxmCjKH"},"outputs":[],"source":["import os\n","import sys"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BCDUFCh7Fd-n"},"outputs":[],"source":["# To add your own Drive Run this cell.\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQXiXrbaF3NK"},"outputs":[],"source":["# Please append your own directory after â€˜/content/drive/My Drive/'\n","### ========== TODO : START ========== ###\n","sys.path += ['/content/drive/My Drive/path_to_your_code']\n","### ========== TODO : END ========== ###"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"7_OLupUPC2U3"},"outputs":[],"source":["\"\"\"\n","Author      : Yi-Chieh Wu, Sriram Sankararman\n","Description : Twitter\n","\"\"\"\n","\n","from string import punctuation\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","# !!! MAKE SURE TO USE LinearSVC.decision_function(X), NOT LinearSVC.predict(X) !!!\n","# (this makes ''continuous-valued'' predictions)\n","from sklearn.svm import LinearSVC\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn import metrics"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"47L2XVzBX6c5"},"source":["# Problem 3: Twitter Analysis Using SVM"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"9Z8E5YL0CzWe"},"outputs":[],"source":["######################################################################\n","# functions -- input/output\n","######################################################################\n","\n","def read_vector_file(fname):\n","    \"\"\"\n","    Reads and returns a vector from a file.\n","\n","    Parameters\n","    --------------------\n","        fname  -- string, filename\n","\n","    Returns\n","    --------------------\n","        labels -- numpy array of shape (n,)\n","                    n is the number of non-blank lines in the text file\n","    \"\"\"\n","    return np.genfromtxt(fname)\n","\n","\n","def write_label_answer(vec, outfile):\n","    \"\"\"\n","    Writes your label vector to the given file.\n","\n","    Parameters\n","    --------------------\n","        vec     -- numpy array of shape (n,) or (n,1), predicted scores\n","        outfile -- string, output filename\n","    \"\"\"\n","\n","    # for this project, you should predict 70 labels\n","    if(vec.shape[0] != 70):\n","        print(\"Error - output vector should have 70 rows.\")\n","        print(\"Aborting write.\")\n","        return\n","\n","    np.savetxt(outfile, vec)\n","    "]},{"cell_type":"code","execution_count":11,"metadata":{"id":"i67aTAmrGGHi"},"outputs":[],"source":["######################################################################\n","# functions -- feature extraction\n","######################################################################\n","\n","def extract_words(input_string):\n","    \"\"\"\n","    Processes the input_string, separating it into \"words\" based on the presence\n","    of spaces, and separating punctuation marks into their own words.\n","\n","    Parameters\n","    --------------------\n","        input_string -- string of characters\n","\n","    Returns\n","    --------------------\n","        words        -- list of lowercase \"words\"\n","    \"\"\"\n","\n","    for c in punctuation :\n","        input_string = input_string.replace(c, ' ' + c + ' ')\n","    return input_string.lower().split()\n","\n","\n","def extract_dictionary(infile):\n","    \"\"\"\n","    Given a filename, reads the text file and builds a dictionary of unique\n","    words/punctuations.\n","\n","    Parameters\n","    --------------------\n","        infile    -- string, filename\n","\n","    Returns\n","    --------------------\n","        word_list -- dictionary, (key, value) pairs are (word, index)\n","    \"\"\"\n","\n","    word_list = {}\n","    idx = 0\n","    with open(infile, 'r') as fid :\n","        # process each line to populate word_list\n","        for input_string in fid:\n","            words = extract_words(input_string)\n","            for word in words:\n","                if word not in word_list:\n","                    word_list[word] = idx\n","                    idx += 1\n","    return word_list\n","\n","\n","def extract_feature_vectors(infile, word_list):\n","    \"\"\"\n","    Produces a bag-of-words representation of a text file specified by the\n","    filename infile based on the dictionary word_list.\n","\n","    Parameters\n","    --------------------\n","        infile         -- string, filename\n","        word_list      -- dictionary, (key, value) pairs are (word, index)\n","\n","    Returns\n","    --------------------\n","        feature_matrix -- numpy array of shape (n,d)\n","                          boolean (0,1) array indicating word presence in a string\n","                            n is the number of non-blank lines in the text file\n","                            d is the number of unique words in the text file\n","    \"\"\"\n","\n","    num_lines = sum(1 for line in open(infile,'r'))\n","    num_words = len(word_list)\n","    feature_matrix = np.zeros((num_lines, num_words))\n","\n","    with open(infile, 'r') as fid :\n","        # process each line to populate feature_matrix\n","        for i, input_string in enumerate(fid):\n","            words = extract_words(input_string)\n","            for word in words:\n","                feature_matrix[i, word_list[word]] = 1.0\n","\n","    return feature_matrix"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"-MvTxQPRGOOf"},"outputs":[],"source":["######################################################################\n","# functions -- evaluation\n","######################################################################\n","\n","def performance(y_true, y_pred, metric=\"accuracy\"):\n","    \"\"\"\n","    Calculates the performance metric based on the agreement between the\n","    true labels and the predicted labels.\n","\n","    Parameters\n","    --------------------\n","        y_true -- numpy array of shape (n,), known labels\n","        y_pred -- numpy array of shape (n,), (continuous-valued) predictions\n","        metric -- string, option used to select the performance measure\n","                  options: 'accuracy', 'f1-score', 'auroc', 'precision',\n","                           'sensitivity', 'specificity'\n","\n","    Returns\n","    --------------------\n","        score  -- float, performance score\n","    \"\"\"\n","    # map continuous-valued predictions to binary labels\n","    y_label = np.sign(y_pred)\n","    y_label[y_label==0] = 1\n","\n","    ### ========== TODO : START ========== ###\n","    # part 1a: compute classifier performance\n","    \n","    if metric == \"accuracy\":\n","        score = metrics.accuracy_score(y_true, y_pred)\n","    elif metric == \"f1-score\":\n","        score = metrics.f1_score(y_true, y_pred)\n","    elif metric == \"auroc\":\n","        score = metrics.roc_auc_score(y_true, y_pred)\n","    elif metric == \"precision\":\n","        score = metrics.precision_score(y_true, y_pred)\n","    elif metric == \"sensitivity\": #same as recall\n","        score = metrics.recall_score(y_true, y_pred)\n","    elif metric == \"specificity\":\n","        tn, fp, _, _ = metrics.confusion_matrix(y_true, y_label).ravel()\n","        return tn / (tn + fp)\n","\n","    return score\n","    ### ========== TODO : END ========== ###\n","\n","\n","def cv_performance(clf, X, y, kf, metric=\"accuracy\"):\n","    \"\"\"\n","    Splits the data, X and y, into k-folds and runs k-fold cross-validation.\n","    Trains classifier on k-1 folds and tests on the remaining fold.\n","    Calculates the k-fold cross-validation performance metric for classifier\n","    by averaging the performance across folds.\n","\n","    Parameters\n","    --------------------\n","        clf    -- classifier (instance of LinearSVC)\n","        X      -- numpy array of shape (n,d), feature vectors\n","                    n = number of examples\n","                    d = number of features\n","        y      -- numpy array of shape (n,), binary labels {1,-1}\n","        kf     -- model_selection.StratifiedKFold\n","        metric -- string, option used to select performance measure\n","\n","    Returns\n","    --------------------\n","        score   -- float, average cross-validation performance across k folds\n","    \"\"\"\n","\n","    ### ========== TODO : START ========== ###\n","    # part 1b: compute average cross-validation performance\n","    scores = []\n","\n","    for train_index, test_index in kf.split(X, y):\n","        X_train, X_test = X[train_index], X[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","\n","        clf.fit(X_train, y_train)\n","\n","        y_scores = clf.decision_function(X_test)\n","\n","        if metric == \"auroc\":\n","            score = performance(y_test, y_scores, metric)\n","        else:\n","            y_pred = np.sign(y_scores)\n","            y_pred[y_pred == 0] = 1\n","            score = performance(y_test, y_pred, metric)\n","\n","        scores.append(score)\n","    \n","    return np.mean(scores)\n","    ### ========== TODO : END ========== ###\n","\n","\n","def select_param_linear(X, y, kf, metric=\"accuracy\"):\n","    \"\"\"\n","    Sweeps different settings for the hyperparameter of a linear SVM,\n","    calculating the k-fold CV performance for each setting, then selecting the\n","    hyperparameter that 'maximize' the average k-fold CV performance.\n","\n","    Parameters\n","    --------------------\n","        X      -- numpy array of shape (n,d), feature vectors\n","                    n = number of examples\n","                    d = number of features\n","        y      -- numpy array of shape (n,), binary labels {1,-1}\n","        kf     -- model_selection.StratifiedKFold\n","        metric -- string, option used to select performance measure\n","\n","    Returns\n","    --------------------\n","        C -- float, optimal parameter value for linear SVM\n","    \"\"\"\n","\n","    print('Linear SVM Hyperparameter Selection based on ' + str(metric) + ':')\n","    C_range = 10.0 ** np.arange(-3, 3)\n","\n","    ### ========== TODO : START ========== ###\n","    # part 1c: select optimal hyperparameter using cross-validation\n","    \n","    best_score = 0\n","    best_C = None\n","\n","    for C in C_range:\n","        clf = LinearSVC(loss = 'hinge', random_state=0, C=C)\n","        score = cv_performance(clf, X, y, kf, metric)\n","        if score > best_score:\n","            best_score = score\n","            best_C = C\n","            \n","    print(\"For {}: Best C = {:.3f}. Best Score = {:.3f}\".format(metric, best_C, best_score))\n","\n","    return best_C\n","    ### ========== TODO : END ========== ###\n","\n","\n","def performance_test(clf, X, y, metric=\"accuracy\"):\n","    \"\"\"\n","    Estimates the performance of the classifier.\n","\n","    Parameters\n","    --------------------\n","        clf          -- classifier (instance of LinearSVC)\n","                          [already fit to data]\n","        X            -- numpy array of shape (n,d), feature vectors of test set\n","                          n = number of examples\n","                          d = number of features\n","        y            -- numpy array of shape (n,), binary labels {1,-1} of test set\n","        metric       -- string, option used to select performance measure\n","\n","    Returns\n","    --------------------\n","        score        -- float, classifier performance\n","    \"\"\"\n","\n","\n","    ### ========== TODO : START ========== ###\n","    # part 2b: return performance on test data under a metric.\n","    y_scores = clf.decision_function(X)\n","\n","    if metric != \"auroc\":\n","        y_pred = np.sign(y_scores)\n","        y_pred[y_pred == 0] = 1\n","    else:\n","        y_pred = y_scores\n","\n","    # Use the performance function to calculate the score\n","    score = performance(y, y_pred, metric)\n","    return score\n","\n","    ### ========== TODO : END ========== ###"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"zMIQRGpYErVF"},"outputs":[{"name":"stdout","output_type":"stream","text":["1811\n","Linear SVM Hyperparameter Selection based on accuracy:\n","For accuracy: Best C = 10.000. Best Score = 0.829\n","Linear SVM Hyperparameter Selection based on f1-score:\n","For f1-score: Best C = 10.000. Best Score = 0.883\n","Linear SVM Hyperparameter Selection based on auroc:\n","For auroc: Best C = 10.000. Best Score = 0.895\n","Linear SVM Hyperparameter Selection based on precision:\n","For precision: Best C = 10.000. Best Score = 0.856\n","Linear SVM Hyperparameter Selection based on sensitivity:\n","For sensitivity: Best C = 0.001. Best Score = 1.000\n","Linear SVM Hyperparameter Selection based on specificity:\n","For specificity: Best C = 10.000. Best Score = 0.625\n","Performance for accuracy with C=10.0: 0.7428571428571429\n","Performance for f1-score with C=10.0: 0.43749999999999994\n","Performance for auroc with C=10.0: 0.7453838678328474\n","Performance for precision with C=10.0: 0.6363636363636364\n","Performance for sensitivity with C=10.0: 1.0\n","Performance for specificity with C=10.0: 0.9183673469387755\n"]}],"source":["######################################################################\n","# main\n","######################################################################\n","\n","def main() :\n","    np.random.seed(1234)\n","\n","    # read the tweets and its labels, change the following two lines to your own path.\n","    ### ========== TODO : START ========== ###\n","    file_path = '../data/tweets.txt'\n","    label_path = '../data/labels.txt'\n","    ### ========== TODO : END ========== ###\n","    dictionary = extract_dictionary(file_path)\n","    print(len(dictionary))\n","    X = extract_feature_vectors(file_path, dictionary)\n","    y = read_vector_file(label_path)\n","    # split data into training (training + cross-validation) and testing set\n","    X_train, X_test = X[:560], X[560:]\n","    y_train, y_test = y[:560], y[560:]\n","\n","    metric_list = [\"accuracy\", \"f1-score\", \"auroc\", \"precision\", \"sensitivity\", \"specificity\"]\n","\n","    ### ========== TODO : START ========== ###\n","    # part 1b: create stratified folds (5-fold CV)\n","    kf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 0)\n","    \n","    # part 1c: for each metric, select optimal hyperparameter for linear SVM using CV\n","    best_C_values = {}\n","    for metric in metric_list:\n","        best_C_values[metric] = select_param_linear(X_train, y_train, kf, metric)\n","\n","    # part 2a: train linear SVMs with selected hyperparameters\n","    classifiers = {}\n","    for metric, C in best_C_values.items():\n","        clf = LinearSVC(loss='hinge', random_state=0, C=C)\n","        clf.fit(X_train, y_train)\n","        classifiers[metric] = clf\n","\n","    # part 2b: test the performance of your classifiers.\n","    for metric, clf in classifiers.items():\n","        score = performance_test(clf, X_test, y_test, metric)\n","        print(f\"Performance for {metric} with C={C}: {score}\")\n","    ### ========== TODO : END ========== ###\n","\n","\n","if __name__ == \"__main__\" :\n","    main()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_W-_mjX0JMes"},"source":["# Problem 4: Boosting vs. Decision Tree"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"0uzCdPTkOQSY"},"outputs":[],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import metrics\n","from sklearn.model_selection import cross_val_score, train_test_split"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"DVxef2sxOmVI"},"outputs":[],"source":["class Data :\n","    \n","    def __init__(self) :\n","        \"\"\"\n","        Data class.\n","        \n","        Attributes\n","        --------------------\n","            X -- numpy array of shape (n,d), features\n","            y -- numpy array of shape (n,), targets\n","        \"\"\"\n","                \n","        # n = number of examples, d = dimensionality\n","        self.X = None\n","        self.y = None\n","        \n","        self.Xnames = None\n","        self.yname = None\n","    \n","    def load(self, filename, header=0, predict_col=-1) :\n","        \"\"\"Load csv file into X array of features and y array of labels.\"\"\"\n","        \n","        # determine filename\n","        f = filename\n","        \n","        # load data\n","        with open(f, 'r') as fid :\n","            data = np.loadtxt(fid, delimiter=\",\", skiprows=header)\n","        \n","        # separate features and labels\n","        if predict_col is None :\n","            self.X = data[:,:]\n","            self.y = None\n","        else :\n","            if data.ndim > 1 :\n","                self.X = np.delete(data, predict_col, axis=1)\n","                self.y = data[:,predict_col]\n","            else :\n","                self.X = None\n","                self.y = data[:]\n","        \n","        # load feature and label names\n","        if header != 0:\n","            with open(f, 'r') as fid :\n","                header = fid.readline().rstrip().split(\",\")\n","                \n","            if predict_col is None :\n","                self.Xnames = header[:]\n","                self.yname = None\n","            else :\n","                if len(header) > 1 :\n","                    self.Xnames = np.delete(header, predict_col)\n","                    self.yname = header[predict_col]\n","                else :\n","                    self.Xnames = None\n","                    self.yname = header[0]\n","        else:\n","            self.Xnames = None\n","            self.yname = None\n","\n","\n","# helper functions\n","def load_data(filename, header=0, predict_col=-1) :\n","    \"\"\"Load csv file into Data class.\"\"\"\n","    data = Data()\n","    data.load(filename, header=header, predict_col=predict_col)\n","    return data"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"_Zcf4WVqJSpe"},"outputs":[],"source":["# Change the path to your own data directory\n","### ========== TODO : START ========== ###\n","titanic = load_data(\"../data/titanic_train.csv\", header=1, predict_col=0)\n","### ========== TODO : END ========== ###\n","X = titanic.X; Xnames = titanic.Xnames\n","y = titanic.y; yname = titanic.yname\n","n,d = X.shape  # n = number of examples, d =  number of features"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"3Ta7XHRWQGNo"},"outputs":[],"source":["def error(clf, X, y, ntrials=100, test_size=0.2) :\n","    \"\"\"\n","    Computes the classifier error over a random split of the data,\n","    averaged over ntrials runs.\n","\n","    Parameters\n","    --------------------\n","        clf         -- classifier\n","        X           -- numpy array of shape (n,d), features values\n","        y           -- numpy array of shape (n,), target classes\n","        ntrials     -- integer, number of trials\n","        test_size   -- proportion of data used for evaluation\n","\n","    Returns\n","    --------------------\n","        train_error -- float, training error\n","        test_error  -- float, test error\n","    \"\"\"\n","\n","    train_error = 0\n","    test_error = 0\n","\n","    train_scores = []; test_scores = [];\n","    for i in range(ntrials):\n","        xtrain, xtest, ytrain, ytest = train_test_split (X,y, test_size = test_size, random_state = i)\n","        clf.fit (xtrain, ytrain)\n","\n","        ypred = clf.predict (xtrain)\n","        err = 1 - metrics.accuracy_score (ytrain, ypred, normalize = True)\n","        train_scores.append (err)\n","\n","        ypred = clf.predict (xtest)\n","        err = 1 - metrics.accuracy_score (ytest, ypred, normalize = True)\n","        test_scores.append (err)\n","\n","    train_error =  np.mean (train_scores)\n","    test_error = np.mean (test_scores)\n","    return train_error, test_error\n"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"W8-U3un5PjGq"},"outputs":[{"name":"stdout","output_type":"stream","text":["Classifying using Decision Tree...\n","Training Error: 0.014044943820224698\n","Average Training Error after 100 trials: 0.011528998242530775\n","Average Test Error after 100 trials: 0.24104895104895108\n"]}],"source":["### ========== TODO : START ========== ###\n","# Part 4(a): Implement the decision tree classifier and report the training error.\n","print('Classifying using Decision Tree...')\n","clf = DecisionTreeClassifier(criterion='entropy', random_state=0)\n","clf.fit(X, y)\n","ypred_train = clf.predict(X)\n","train_error = 1 - metrics.accuracy_score(y, ypred_train)\n","print(f\"Training Error: {train_error}\")\n","train_error, test_error = error(clf, X, y)\n","print(f\"Average Training Error after 100 trials: {train_error}\")\n","print(f\"Average Test Error after 100 trials: {test_error}\")\n","### ========== TODO : END ========== ###"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"_x_PevK8Q4dx"},"outputs":[{"name":"stdout","output_type":"stream","text":["Classifying using Random Forest...\n","Best setting for max_samples: 142 samples\n","Training Error for this setting: 0.10314586994727591\n","Test Error for this setting: 0.18797202797202794\n"]}],"source":["### ========== TODO : START ========== ###\n","# Part 4(b): Implement the random forest classifier and adjust the number of samples used in bootstrap sampling.\n","print('Classifying using Random Forest...')\n","n_samples = len(X)  # Total number of samples in your data\n","max_samples_options = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n","    \n","best_test_error = float('inf')\n","best_max_samples = None\n","best_train_error = None\n","\n","for max_samples_ratio in max_samples_options:\n","    max_samples = int(n_samples * max_samples_ratio)\n","    clf = RandomForestClassifier(criterion='entropy', random_state=0, max_samples=max_samples)\n","        \n","    # Use the provided error function to get training and test error\n","    train_error, test_error = error(clf, X, y)\n","\n","    if test_error < best_test_error:\n","        best_test_error = test_error\n","        best_train_error = train_error\n","        best_max_samples = max_samples\n","\n","print(f\"Best setting for max_samples: {best_max_samples} samples\")\n","print(f\"Training Error for this setting: {best_train_error}\")\n","print(f\"Test Error for this setting: {best_test_error}\")\n","### ========== TODO : END ========== ###"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"ZFUyPTPwT53v"},"outputs":[{"name":"stdout","output_type":"stream","text":["Classifying using Random Forest...\n","Best setting for max_features: 3\n","Training Error for this setting: 0.10244288224956065\n","Test Error for this setting: 0.1872727272727273\n"]}],"source":["### ========== TODO : START ========== ###\n","# Part 4(c): Implement the random forest classifier and adjust the number of features for each decision tree.\n","print('Classifying using Random Forest...')\n","best_max_samples = 142\n","    \n","best_test_error = float('inf')\n","best_max_features = None\n","best_train_error = None\n","\n","for max_features in range(1, 8):\n","    clf = RandomForestClassifier(criterion='entropy', random_state=0, max_samples=best_max_samples, max_features=max_features)\n","        \n","    train_error, test_error = error(clf, X, y)\n","\n","    if test_error < best_test_error:\n","        best_test_error = test_error\n","        best_train_error = train_error\n","        best_max_features = max_features\n","\n","print(f\"Best setting for max_features: {best_max_features}\")\n","print(f\"Training Error for this setting: {best_train_error}\")\n","print(f\"Test Error for this setting: {best_test_error}\")\n","### ========== TODO : END ========== ###"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
